{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy-pink/colab-playground/blob/main/3pytorch/PyTorch-%E5%85%A5%E9%97%A8-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E7%AD%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7r4tBtgB68pI"
      },
      "cell_type": "markdown",
      "source": [
        "### 自动求导"
      ]
    },
    {
      "metadata": {
        "id": "NZpx2pJc68pJ"
      },
      "cell_type": "markdown",
      "source": [
        "#### 梯度跟踪"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-15T13:29:48.412322Z",
          "start_time": "2025-04-15T13:29:47.539337Z"
        },
        "id": "4UzuPXeK68pK",
        "outputId": "db401956-2d98-46eb-b1ea-438a99373b6c"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 创建一个需要梯度的张量\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2  # y = x^2\n",
        "\n",
        "# 计算梯度\n",
        "y.backward()  # dy/dx = 2x\n",
        "print(x.grad)  # 输出: tensor(4.) (因为 x=2, 2*2=4)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "GJL2dSn368pL"
      },
      "cell_type": "markdown",
      "source": [
        "#### 多变量梯度 (偏导数)\n",
        "\n",
        "原函数： $y = (x_1 + x_2)^2$  \n",
        "对x1偏导数：$\\frac{\\partial y}{\\partial x_1} = 2(x_1 + x_2)$; 注意：$\\frac{\\partial (x+2)^2}{\\partial x}=2(x+2)$    \n",
        "对x2求偏导: $\\frac{\\partial y}{\\partial x_2} = 2(x_1 + x_2)$"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-15T13:29:51.145023Z",
          "start_time": "2025-04-15T13:29:51.139092Z"
        },
        "id": "2bAE0Hhd68pL",
        "outputId": "37296268-b82b-42b0-9f1b-0b54a5d1ceff"
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y = x.sum() ** 2  # y = (x1 + x2)^2\n",
        "\n",
        "y.backward()\n",
        "print(x.grad)  # x^2的导数是2x， 2*（1+2）=6"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([6., 6.])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "🥤例二\n",
        "$f(u,v) = uv + u^2$  \n",
        "$\\frac{\\partial f(u,v)}{\\partial u} = v + 2u$   \n",
        "$\\frac{\\partial f(u,v)}{\\partial v} = u$"
      ],
      "metadata": {
        "id": "kjnnYTCR96CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u=torch.tensor(1.0,requires_grad=True)\n",
        "v=torch.tensor(2.0,requires_grad=True)\n",
        "f=u*v+u**2\n",
        "f.backward()\n",
        "print(u.grad)\n",
        "print(v.grad)"
      ],
      "metadata": {
        "id": "JlEMcgWn_li3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_DqDSeJ68pM"
      },
      "cell_type": "markdown",
      "source": [
        "#### 动态计算图  \n",
        "PyTorch 的计算图是动态的，每次前向传播都会构建一个新图：\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-15T13:29:57.984356Z",
          "start_time": "2025-04-15T13:29:57.978736Z"
        },
        "id": "tmLvwh8Q68pM",
        "outputId": "d1ae8fc6-f969-4800-b59a-2a9ad5520036"
      },
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return x ** 2 + 2 * x + 1\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = forward(x)\n",
        "y.backward()\n",
        "print(x.grad)  # 输出: tensor(8.) (因为 dy/dx=2x+2=8)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "kz4kHwUI68pM"
      },
      "cell_type": "markdown",
      "source": [
        "#### 梯度积累 与 清零\n",
        "PyTorch 默认会累加梯度，训练时需手动清零："
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-15T13:30:07.400392Z",
          "start_time": "2025-04-15T13:30:07.392438Z"
        },
        "id": "Z--vTe-l68pM",
        "outputId": "cb5cce43-dd36-4e17-8114-32e76ee8bb29"
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# 第一次计算\n",
        "y1 = x ** 2\n",
        "y1.backward()\n",
        "print(x.grad)  # tensor(2.)  2*x\n",
        "\n",
        "# 清零梯度\n",
        "# x.grad.zero_()\n",
        "\n",
        "# 第二次计算（梯度会累加）\n",
        "y2 = x ** 3\n",
        "y2.backward()\n",
        "print(x.grad)  # tensor(5.) 没清0: (2*1 + 3*1^2=5)； 梯度清过0: 3*1^2=3\n",
        "\n",
        "# 清零梯度\n",
        "x.grad.zero_()"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(5.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "_mngujGh68pM"
      },
      "cell_type": "markdown",
      "source": [
        "#### 阻止梯度跟踪\n",
        "\n",
        "detach() 分离张量，使其不参与梯度计算：\n",
        "\n",
        "```python\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "z = y.detach()  # z 不参与梯度计算\n",
        "\n",
        "z.backward()  # 报错！z 无梯度跟踪\n",
        "\n",
        "## 临时禁用梯度计算：\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    y = x ** 2  # y 不记录计算图\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Zt2i41cB68pM"
      },
      "cell_type": "markdown",
      "source": [
        "####  高阶导数"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-15T13:30:11.263015Z",
          "start_time": "2025-04-15T13:30:11.258197Z"
        },
        "id": "K6Sb7Xku68pN",
        "outputId": "c818c3b7-b638-4355-9f7c-fc3e7ad4c9b5"
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 3\n",
        "\n",
        "# 一阶导数\n",
        "grad1 = torch.autograd.grad(y, x, create_graph=True)  # dy/dx=3x^2=12\n",
        "print(grad1[0])  # tensor(12.)\n",
        "\n",
        "# 二阶导数\n",
        "grad2 = torch.autograd.grad(grad1[0], x)  # d²y/dx²=3*2x=12\n",
        "print(grad2[0])  # tensor(12.)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(12., grad_fn=<MulBackward0>)\n",
            "tensor(12.)\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}