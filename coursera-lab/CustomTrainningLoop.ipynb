{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Basic Training Loop",
   "id": "9341dd27d624e411"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T06:33:57.217376Z",
     "start_time": "2025-05-30T06:33:50.998626Z"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 准备数据",
   "id": "97928cb19ed3eb37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:33:57.536411Z",
     "start_time": "2025-05-30T06:33:57.226440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ],
   "id": "231b99f58c719536",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义模型",
   "id": "5d1b92a6b4375292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:34:28.490395Z",
     "start_time": "2025-05-30T06:34:28.469319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ],
   "id": "2950fc52e0453977",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/colab/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义损失函数和优化器",
   "id": "12ed74cff26421c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:34:31.526654Z",
     "start_time": "2025-05-30T06:34:31.520813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = tf.keras.optimizers.Adam()"
   ],
   "id": "ed3d806b5efaa476",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 实现自定义Training Loops",
   "id": "4749b126839310b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:35:05.585517Z",
     "start_time": "2025-05-30T06:34:36.989287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "# train_dataset = train_dataset.repeat(epochs)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)  # Forward pass\n",
    "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Logging the loss every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}')"
   ],
   "id": "71be24fa16a35849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.303683280944824\n",
      "Epoch 1 Step 200: Loss = 0.36938774585723877\n",
      "Epoch 1 Step 400: Loss = 0.18165946006774902\n",
      "Epoch 1 Step 600: Loss = 0.1624484360218048\n",
      "Epoch 1 Step 800: Loss = 0.1730903685092926\n",
      "Epoch 1 Step 1000: Loss = 0.41516339778900146\n",
      "Epoch 1 Step 1200: Loss = 0.189113587141037\n",
      "Epoch 1 Step 1400: Loss = 0.2236395925283432\n",
      "Epoch 1 Step 1600: Loss = 0.2254944145679474\n",
      "Epoch 1 Step 1800: Loss = 0.14914561808109283\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.08540712296962738\n",
      "Epoch 2 Step 200: Loss = 0.16500020027160645\n",
      "Epoch 2 Step 400: Loss = 0.08249332010746002\n",
      "Epoch 2 Step 600: Loss = 0.03424878418445587\n",
      "Epoch 2 Step 800: Loss = 0.0693032518029213\n",
      "Epoch 2 Step 1000: Loss = 0.24864672124385834\n",
      "Epoch 2 Step 1200: Loss = 0.12689433991909027\n",
      "Epoch 2 Step 1400: Loss = 0.13711830973625183\n",
      "Epoch 2 Step 1600: Loss = 0.2093067467212677\n",
      "Epoch 2 Step 1800: Loss = 0.10138417780399323\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 添加 Accuracy 测量",
   "id": "a93e2001f667b330"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 设置环境",
   "id": "26d80ffc94328cd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:36:48.357017Z",
     "start_time": "2025-05-30T06:36:48.049957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Create a batched dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ],
   "id": "7c6ffa787ab790bc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义模型",
   "id": "6ae4d991b1cbb8ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:36:49.769879Z",
     "start_time": "2025-05-30T06:36:49.753026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = Sequential([ \n",
    "    Flatten(input_shape=(28, 28)),  # Flatten the input to a 1D vector\n",
    "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
    "    Dense(10)  # Output layer with 10 neurons for the 10 classes (digits 0-9)\n",
    "])\n"
   ],
   "id": "c335cda4f90ae0cf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义损失函数，优化器和Metric",
   "id": "b61689468989bebb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:36:52.510219Z",
     "start_time": "2025-05-30T06:36:52.503575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
    "optimizer = tf.keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training\n"
   ],
   "id": "64f4acdae1029c21",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 自定义Training Loop",
   "id": "672208f52f0ea5e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:38:14.318240Z",
     "start_time": "2025-05-30T06:36:53.884175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 5  # Number of epochs for training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()"
   ],
   "id": "43f608e8e8402ea2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.390378952026367 Accuracy = 0.0625\n",
      "Epoch 1 Step 200: Loss = 0.41103625297546387 Accuracy = 0.8327114582061768\n",
      "Epoch 1 Step 400: Loss = 0.18913236260414124 Accuracy = 0.8666614890098572\n",
      "Epoch 1 Step 600: Loss = 0.19121761620044708 Accuracy = 0.8824355006217957\n",
      "Epoch 1 Step 800: Loss = 0.1919010579586029 Accuracy = 0.8948969841003418\n",
      "Epoch 1 Step 1000: Loss = 0.41956281661987305 Accuracy = 0.9018169045448303\n",
      "Epoch 1 Step 1200: Loss = 0.2165583223104477 Accuracy = 0.908331573009491\n",
      "Epoch 1 Step 1400: Loss = 0.2494545578956604 Accuracy = 0.9131200909614563\n",
      "Epoch 1 Step 1600: Loss = 0.19828134775161743 Accuracy = 0.9164584875106812\n",
      "Epoch 1 Step 1800: Loss = 0.1927342712879181 Accuracy = 0.9203567504882812\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.06752408295869827 Accuracy = 1.0\n",
      "Epoch 2 Step 200: Loss = 0.17725607752799988 Accuracy = 0.9597325921058655\n",
      "Epoch 2 Step 400: Loss = 0.10160834342241287 Accuracy = 0.9573721885681152\n",
      "Epoch 2 Step 600: Loss = 0.045059897005558014 Accuracy = 0.9595465660095215\n",
      "Epoch 2 Step 800: Loss = 0.1119549572467804 Accuracy = 0.9604400992393494\n",
      "Epoch 2 Step 1000: Loss = 0.25422078371047974 Accuracy = 0.9612575173377991\n",
      "Epoch 2 Step 1200: Loss = 0.12283718585968018 Accuracy = 0.9621409177780151\n",
      "Epoch 2 Step 1400: Loss = 0.13501125574111938 Accuracy = 0.9628836512565613\n",
      "Epoch 2 Step 1600: Loss = 0.13268238306045532 Accuracy = 0.9627576470375061\n",
      "Epoch 2 Step 1800: Loss = 0.08971228450536728 Accuracy = 0.9635098576545715\n",
      "Start of epoch 3\n",
      "Epoch 3 Step 0: Loss = 0.03419957682490349 Accuracy = 1.0\n",
      "Epoch 3 Step 200: Loss = 0.09385576099157333 Accuracy = 0.9737251400947571\n",
      "Epoch 3 Step 400: Loss = 0.10298740118741989 Accuracy = 0.9723348021507263\n",
      "Epoch 3 Step 600: Loss = 0.02713034860789776 Accuracy = 0.9736377000808716\n",
      "Epoch 3 Step 800: Loss = 0.06863939017057419 Accuracy = 0.9737047553062439\n",
      "Epoch 3 Step 1000: Loss = 0.11795298010110855 Accuracy = 0.9741820693016052\n",
      "Epoch 3 Step 1200: Loss = 0.07302979379892349 Accuracy = 0.9744223356246948\n",
      "Epoch 3 Step 1400: Loss = 0.07659889757633209 Accuracy = 0.9748170971870422\n",
      "Epoch 3 Step 1600: Loss = 0.07638385146856308 Accuracy = 0.9745861887931824\n",
      "Epoch 3 Step 1800: Loss = 0.041022565215826035 Accuracy = 0.975135326385498\n",
      "Start of epoch 4\n",
      "Epoch 4 Step 0: Loss = 0.02670876868069172 Accuracy = 1.0\n",
      "Epoch 4 Step 200: Loss = 0.041571348905563354 Accuracy = 0.9822761416435242\n",
      "Epoch 4 Step 400: Loss = 0.07306685298681259 Accuracy = 0.9811409115791321\n",
      "Epoch 4 Step 600: Loss = 0.03544452786445618 Accuracy = 0.981697142124176\n",
      "Epoch 4 Step 800: Loss = 0.043516162782907486 Accuracy = 0.9812343716621399\n",
      "Epoch 4 Step 1000: Loss = 0.07931362092494965 Accuracy = 0.9817057847976685\n",
      "Epoch 4 Step 1200: Loss = 0.033704452216625214 Accuracy = 0.9817860126495361\n",
      "Epoch 4 Step 1400: Loss = 0.048891954123973846 Accuracy = 0.9817541241645813\n",
      "Epoch 4 Step 1600: Loss = 0.057354919612407684 Accuracy = 0.9817301630973816\n",
      "Epoch 4 Step 1800: Loss = 0.027788519859313965 Accuracy = 0.9820759296417236\n",
      "Start of epoch 5\n",
      "Epoch 5 Step 0: Loss = 0.028521450236439705 Accuracy = 1.0\n",
      "Epoch 5 Step 200: Loss = 0.009288536384701729 Accuracy = 0.9877176880836487\n",
      "Epoch 5 Step 400: Loss = 0.06130247563123703 Accuracy = 0.9866739511489868\n",
      "Epoch 5 Step 600: Loss = 0.050193704664707184 Accuracy = 0.9872608184814453\n",
      "Epoch 5 Step 800: Loss = 0.027363527566194534 Accuracy = 0.9869303703308105\n",
      "Epoch 5 Step 1000: Loss = 0.06229348108172417 Accuracy = 0.9870754480361938\n",
      "Epoch 5 Step 1200: Loss = 0.02284584939479828 Accuracy = 0.9866517782211304\n",
      "Epoch 5 Step 1400: Loss = 0.014302443712949753 Accuracy = 0.9865720868110657\n",
      "Epoch 5 Step 1600: Loss = 0.04606063663959503 Accuracy = 0.9866880178451538\n",
      "Epoch 5 Step 1800: Loss = 0.016559245064854622 Accuracy = 0.9867955446243286\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Callback for Advanced Logging",
   "id": "3f00a5a24696c35f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:39:40.292067Z",
     "start_time": "2025-05-30T06:39:40.012300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Create a batched dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n"
   ],
   "id": "2271ffed3ccfd1a6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:39:42.260579Z",
     "start_time": "2025-05-30T06:39:42.249933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Flatten the input to a 1D vector\n",
    "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
    "    Dense(10)  # Output layer with 10 neurons for the 10 classes (digits 0-9)\n",
    "])"
   ],
   "id": "ce9d2b695ab18501",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:40:31.698761Z",
     "start_time": "2025-05-30T06:40:31.694141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
    "optimizer = tf.keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ],
   "id": "3dfd1ea9933d95f3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:39:43.357768Z",
     "start_time": "2025-05-30T06:39:43.355295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Step 4: Implement the Custom Callback \n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f'End of epoch {epoch + 1}, loss: {logs.get(\"loss\")}, accuracy: {logs.get(\"accuracy\")}')\n"
   ],
   "id": "ce91f84fa33b85bf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:05.392973Z",
     "start_time": "2025-05-30T06:40:33.649347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "epochs = 2\n",
    "custom_callback = CustomCallback()  # Initialize the custom callback\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Call the custom callback at the end of each epoch\n",
    "    custom_callback.on_epoch_end(epoch, logs={'loss': loss_value.numpy(), 'accuracy': accuracy_metric.result().numpy()})\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()  # Use reset_sta"
   ],
   "id": "692af3c16e09aa5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.327249526977539 Accuracy = 0.15625\n",
      "Epoch 1 Step 200: Loss = 0.36825716495513916 Accuracy = 0.8404850959777832\n",
      "Epoch 1 Step 400: Loss = 0.16387075185775757 Accuracy = 0.8716490268707275\n",
      "Epoch 1 Step 600: Loss = 0.14201074838638306 Accuracy = 0.885503351688385\n",
      "Epoch 1 Step 800: Loss = 0.18003690242767334 Accuracy = 0.896847665309906\n",
      "Epoch 1 Step 1000: Loss = 0.36329495906829834 Accuracy = 0.9035027623176575\n",
      "Epoch 1 Step 1200: Loss = 0.17180293798446655 Accuracy = 0.9097887277603149\n",
      "Epoch 1 Step 1400: Loss = 0.2600264251232147 Accuracy = 0.9145476222038269\n",
      "Epoch 1 Step 1600: Loss = 0.2697421610355377 Accuracy = 0.9177076816558838\n",
      "Epoch 1 Step 1800: Loss = 0.18687570095062256 Accuracy = 0.9215887188911438\n",
      "End of epoch 1, loss: 0.035480670630931854, accuracy: 0.9235166907310486\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.07216691970825195 Accuracy = 1.0\n",
      "Epoch 2 Step 200: Loss = 0.1736968457698822 Accuracy = 0.9597325921058655\n",
      "Epoch 2 Step 400: Loss = 0.08797873556613922 Accuracy = 0.9555018544197083\n",
      "Epoch 2 Step 600: Loss = 0.04067816585302353 Accuracy = 0.958246648311615\n",
      "Epoch 2 Step 800: Loss = 0.06260693073272705 Accuracy = 0.9601669907569885\n",
      "Epoch 2 Step 1000: Loss = 0.2896285653114319 Accuracy = 0.9606019258499146\n",
      "Epoch 2 Step 1200: Loss = 0.1086004301905632 Accuracy = 0.9618287086486816\n",
      "Epoch 2 Step 1400: Loss = 0.1576017290353775 Accuracy = 0.962593674659729\n",
      "Epoch 2 Step 1600: Loss = 0.19130201637744904 Accuracy = 0.9627381563186646\n",
      "Epoch 2 Step 1800: Loss = 0.1228925809264183 Accuracy = 0.9634057283401489\n",
      "End of epoch 2, loss: 0.0321052260696888, accuracy: 0.9640499949455261\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 添加隐藏层",
   "id": "d6d880de2d5fd9ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:09.597297Z",
     "start_time": "2025-05-30T06:41:09.586989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(28, 28))  # Input layer with shape (28, 28)\n",
    "\n",
    "# Define hidden layers\n",
    "hidden_layer1 = Dense(64, activation='relu')(input_layer)  # First hidden layer with 64 neurons and ReLU activation\n",
    "hidden_layer2 = Dense(64, activation='relu')(hidden_layer1)  # Second hidden layer with 64 neurons and ReLU activation\n"
   ],
   "id": "5b466e402ebbcdca",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:11.816089Z",
     "start_time": "2025-05-30T06:41:11.809563Z"
    }
   },
   "cell_type": "code",
   "source": "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)",
   "id": "42d4d1c24288be52",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:13.484090Z",
     "start_time": "2025-05-30T06:41:13.480002Z"
    }
   },
   "cell_type": "code",
   "source": "model = Model(inputs=input_layer, outputs=output_layer)",
   "id": "7443ebcf1d6bbe7e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:15.428311Z",
     "start_time": "2025-05-30T06:41:15.422306Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])",
   "id": "d93f19e3065113e7",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:17.830115Z",
     "start_time": "2025-05-30T06:41:17.062688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Redefine the Model for 20 features\n",
    "model = Sequential([\n",
    "    Input(shape=(20,)),  # Adjust input shape to (20,)\n",
    "    Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification with sigmoid activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 2: Generate Example Data\n",
    "X_train = np.random.rand(1000, 20)  # 1000 samples, 20 features each\n",
    "y_train = np.random.randint(2, size=(1000, 1))  # 1000 binary labels (0 or 1)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ],
   "id": "b7f8e7cd11a713ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 822us/step - accuracy: 0.4840 - loss: 0.7009 \n",
      "Epoch 2/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 829us/step - accuracy: 0.5343 - loss: 0.6909\n",
      "Epoch 3/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 834us/step - accuracy: 0.5175 - loss: 0.6935\n",
      "Epoch 4/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852us/step - accuracy: 0.5467 - loss: 0.6915\n",
      "Epoch 5/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 810us/step - accuracy: 0.5273 - loss: 0.6884\n",
      "Epoch 6/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 808us/step - accuracy: 0.5647 - loss: 0.6842\n",
      "Epoch 7/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - accuracy: 0.5291 - loss: 0.6872\n",
      "Epoch 8/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - accuracy: 0.5707 - loss: 0.6813\n",
      "Epoch 9/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - accuracy: 0.5537 - loss: 0.6849\n",
      "Epoch 10/10\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.5828 - loss: 0.6794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31bab5b10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T06:41:23.400094Z",
     "start_time": "2025-05-30T06:41:23.315418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test = np.random.rand(200, 20)  # 200 samples, 20 features each\n",
    "y_test = np.random.randint(2, size=(200, 1))  # 200 binary labels (0 or 1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print test loss and accuracy\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ],
   "id": "e1c256b3cea244cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4735 - loss: 0.6996 \n",
      "Test loss: 0.6979187726974487\n",
      "Test accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
